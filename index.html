<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Learning Long-Context Robot Policies via Past-Token Prediction">
  <meta name="keywords" content="PTP, Long-Context, Robot Learning, Imitation Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning Long-Context Robot Policies via Past-Token Prediction</title>

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- Fonts and Styles -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/stanford.png">

  <!-- Scripts -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style>
    .video-row {
      margin-bottom: 20px;
      padding: 10px;
      border-radius: 8px;
      box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.20);
      background-color: #f9f9f9;
    }
    section.section {
      padding-top: 1rem;
      padding-bottom: 1rem;
    }
    .section h2.title, .section h3.subtitle {
      margin-top: 1.5rem;
      margin-bottom: 1rem;
    }
    .section p {
      margin-top: 0.5rem;
      margin-bottom: 0.5rem;
    }
    .section .title.is-3 {
      text-align: center;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Learning Long-Context Robot Policies via Past-Token Prediction</h1>
          <div class="is-size-5 publication-authors">
            <!-- Replace these with your actual authors -->
<!--             <span class="author-block">Author 1<sup>*</sup>,</span>
            <span class="author-block">Author 2<sup>*</sup>,</span>
            <span class="author-block">Author 3,</span>
            <span class="author-block">etc.</span>
 -->          </div>
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
<!--               <div class="column is-four-fifths">
                <figure class="image is-centered" style="margin-bottom: 0;">
                  <img src="./static/images/logo.jpg" alt="Project Logo">
                </figure>
                <h3 class="title is-4" style="margin-top: 8px;">ICLR 2025</h3>
              </div> -->
            </div>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Add links as needed -->
<!--               <span class="link-block">
                <a href="./static/PTP_paper.pdf" class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#BibTeX" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-quote-right"></i></span>
                  <span>BibTeX</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Abstract</h2>
    <p>Reasoning over long sequences of observations and actions is essential for many robotic tasks. Yet, learning effective long-context policies from demonstrations remains challenging. As context length increases, training becomes prohibitively expensive due to the surge of memory demands, and policy performance often degrades due to spurious correlations. Recent methods typically sidestep these issues by truncating context length, discarding potentially critical information for subsequent decisions. In this paper, we propose an alternative approach that explicitly regularizes information retention from past observations. At the core of our method is Past-Token Prediction (PTP), an auxiliary task where the policy learns to predict past action tokens alongside future ones. This simple regularizer significantly strengthens temporal action dependencies, which are commonly lost in recent policies. In particular, we find that the benefit of PTP primarily emerges in the policy head rather than the visual encoder. Building on this observation, we introduce a multistage training strategy: first pre-train the visual encoder with short contexts, then fine-tune the policy head using cached long-context embeddings. This approach preserves the benefits of PTP while greatly reducing memory and computational overhead. Beyond training, we further leverage PTP as a self-verification mechanism, enabling the policy to search for action predictions consistent with past actions at test time. Experiments across seven simulated and four real-world tasks demonstrate that our proposed method improves the performance of long-context policies by 3× and accelerates policy training by more than 10×.
    </p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Analysis: Temporal Action Dependency</h2>
    <p>One major challenge in long-context imitation learning is causal confusion, where policies latch onto spurious correlations in the input context that do not truly influence expert behavior. This issue worsens with longer contexts, leading to overfitting during training and poor generalization at deployment. A classic example is copycat behavior, where the model simply mimics past actions without understanding their relationship to observations. However, our findings reveal a different trend: modern policies tend to under-utilize, rather than over-rely on, temporal action dependencies.
    </p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/baseline_corr.png" style="max-width: 80%;" alt="Image 1 description">
          <figcaption class="has-text-left is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
            Temporal action correlations of baseline policies. Contrary to the Copycat literature, modern behavior cloning (BC) policies often under-utilize temporal action dependencies present in expert demonstrations.
          </figcaption>
        </figure>
      </div>
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/ptp_corr.png" style="max-width: 80%;" alt="Image 2 description">
          <figcaption class="has-text-left is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
            Temporal action correlations of our PTP-trained policies. As supervision over past actions increases (1, 8, 16), policy rollouts exhibit stronger temporal coherence and higher success rate.
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
      <h2 class="title is-3">Method: Past-Token Prediction</h2>
      <p>Building upon our analysis, we introduce a simple yet effective method for long-context imitation learning. At the core is Past-Token Prediction (PTP), an auxiliary objective that tasks the policy to predict both past and future actions. This task encourages the model to better capture action dependencies over time. To scale PTP efficiently, we propose a multi-stage training recipe that freezes a short-horizon encoder, caches visual features, and trains the policy head using these cached embeddings. At test time, we extend PTP into a self-verification mechanism: the policy samples multiple candidate sequences and selects the one that best reconstructs the already-executed actions.
      </p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/train.png" style="max-width: 80%;" alt="Image 1 description">
          <figcaption class="has-text-centered is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
            PTP training with cached embeddings. 
          </figcaption>
        </figure>
      </div>
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/test.png" style="max-width: 100%;" alt="Image 2 description">
          <figcaption class="has-text-centered is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
            PTP inference with self-verification. 
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Simulation Experiments</h2>
    <p>We evaluate our method on seven simulation tasks, including five from the RobotMimic benchmark and two newly designed long-horizon tasks that require historical context. Our approach significantly outperforms short-context and long-context baselines, especially in challenging manipulation scenarios.
</p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/sim_result.png" style="max-width: 80%;" alt="Image 1 description">
          <figcaption class="has-text-left is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Real-World Experiments</h2>
    <p>We evaluate our method on four real-world tasks, each requiring historical context for task completion:</p>
    <ul class="has-text-left" style="margin-left: 1.5rem; list-style-type: disc;">
      <li><em>Franka Block Move</em>: Move a block from one side to the other. History is needed to infer the correct target side.</li>
      <li><em>Franka Two Scoops</em>: Scoop and move two items to a target. History is required to keep count of how many scoops have been made.</li>
      <li><em>Franka Mug Replacement</em>: Replace an old mug with a new one. History helps distinguish between the two mugs.</li>
      <li><em>Aloha Tape Replacement</em>: Replace an old tape roll with a new one. History is necessary to identify the correct tape to remove.</li>
    </ul>
    <p>Our method consistently outperforms both short-context and long-context baselines across all four tasks.</p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/real_result.png" style="max-width: 65%;" alt="Image 1 description">
          <figcaption class="has-text-left is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- <h2 class="title is-3">Real-World Rollouts</h2> -->
    <p class="mb-4">Below are representative vidoes of each method across the four real-world tasks.</p>

    <!-- Table headers -->
    <div class="columns has-text-centered is-mobile is-vcentered mb-3">
      <div class="column"><strong>Short-Context BC</strong></div>
      <div class="column"><strong>Long-Context BC</strong></div>
      <div class="column"><strong>PTP (Ours)</strong></div>
    </div>

    <!-- Row: Task 1 -->
    <h3 class="subtitle is-6 has-text-left mb-2">Franka Block Move</h3>
    <div class="columns is-mobile is-vcentered">
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/block_short.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/block_long.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/block_ptp.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>

    <!-- Row: Task 2 -->
    <h3 class="subtitle is-6 has-text-left mt-5 mb-2">Franka Two Scoops</h3>
    <div class="columns is-mobile is-vcentered">
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/scoop_short.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/scoop_long.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/scoop_ptp.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <!-- Row: Task 3 -->
    <h3 class="subtitle is-6 has-text-left mt-5 mb-2">Franka Mug Replacement</h3>
    <div class="columns is-mobile is-vcentered">
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/mug_short.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/mug_long.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/mug_ptp.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <!-- Row: Task 4 -->
    <h3 class="subtitle is-6 has-text-left mt-5 mb-2">Aloha Tape Replacement</h3>
    <div class="columns is-mobile is-vcentered">
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/tape_short.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/tape_long.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video controls width="100%">
          <source src="./static/videos/tape_ptp.mp4" type="video/mp4">
        </video>
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ptp2025,
  title={Learning Long-Context Robot Policies via Past-Token Prediction},
  year={2025},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="content has-text-centered">
    <span class="author-block"><sup>*</sup>Equal Contribution</span>
  </div>
  <div class="container">
    <div class="content has-text-centered">
      <p>Page template adapted from <a href="https://nerfies.github.io/">Nerfies</a>.</p>
    </div>
  </div>
</footer>

</body>
</html>
