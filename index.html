<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Learning Long-Context Diffusion Policies via Past-Token Prediction">
  <meta name="keywords" content="PTP, Long-Context, Robot Learning, Imitation Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning Long-Context Diffusion Policies via Past-Token Prediction</title>

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- Fonts and Styles -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/stanford.png">

  <!-- Scripts -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style>
    .video-row {
      margin-bottom: 20px;
      padding: 10px;
      border-radius: 8px;
      box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.20);
      background-color: #f9f9f9;
    }
    section.section {
      padding-top: 1rem;
      padding-bottom: 1rem;
    }
    .section h2.title, .section h3.subtitle {
      margin-top: 1.5rem;
      margin-bottom: 1rem;
    }
    .section p {
      margin-top: 0.5rem;
      margin-bottom: 0.5rem;
      text-align: justify;
    }
    .section .title.is-3 {
      text-align: center;
    }
    .columns.is-vcentered > .column {
      display: flex;
      flex-direction: column;
      align-items: stretch; /* makes all columns the same height */
      justify-content: center;
    }
    .equal-height-figure {
      display: flex;
      flex-direction: column;
      justify-content: space-between;
      align-items: center; /* centers contents inside the figure */
      height: 100%;
/*      margin-bottom: 0 !important;*/
      margin: 0 auto; /* centers the figure in the column */
      box-sizing: border-box;
    }
    .hero {
      padding-bottom: 0.0rem !important; /* reduce spacing under the hero */
    }
    .hero-body {
      padding-bottom: 0.0rem !important; /* tighten vertical spacing inside hero */
    }
    .black-link, .black-link:visited, .black-link:hover, .black-link:active {
      color: black;
      text-decoration: none;
    }
    .title.is-4 {
      margin-top: 0 !important;
      margin-bottom: 0 !important;
      padding-top: 0 !important;
      padding-bottom: 0 !important;
      line-height: 1.2 !important;
    }
    #BibTeX pre {
      margin: 0;
      padding: 0.0rem;
      background-color: #f5f5f5;
      border-radius: 0px;
      overflow-x: auto;
    }
    #BibTeX code {
      font-family: monospace;
      white-space: pre;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Learning Long-Context Diffusion Policies via Past-Token Prediction</h1>
          <div class="is-size-5 publication-authors">

          <!-- Author Info Start -->
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="https://marceltorne.github.io/">Marcel Torne</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://www.andyta.ng/">Andy Tang</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/view/yuejiangliu/home">Yuejiang Liu</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
            </span>
          </div>
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <figure class="image is-centered" style="margin-bottom: 0;">
                  <img src="./static/images/logo.jpg" alt="Stanford University">
                </figure>
                <!-- <h3 class="title is-4" style="margin-top: 8px;"> 2025</h3> -->
              </div>
            </div>
            <div class="columns is-centered has-text-centered">
              <div class="column is-full">
                <!-- <h3 class="title is-4 my-2" style="margin-top: 0.0rem; margin-bottom: 0.0rem;"> -->
                <h3 class="title is-4" style="margin: 0; padding: 0; line-height: 1.2;">
                  <a href="https://rss25-roboreps.github.io/" target="_blank" class="black-link">
                    Best Paper at RSS RoboReps 2025
                  </a>
                </h3>
              </div>
            </div>
          </div>          
          <!-- Author Info End -->
          <div class="column has-text-centered">
            <div class="publication-links">
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.09561"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/long-context-dp/ldp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Github</span>
                  </a>
              </span>
              <!-- Add links as needed -->
<!--               <span class="link-block">
                <a href="./static/PTP_paper.pdf" class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#BibTeX" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-quote-right"></i></span>
                  <span>BibTeX</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <video width="720" controls>
        <source src="./static/videos/ptp_arxiv_video_compressed.mp4" type="video/mp4">
        <!-- Your browser does not support the video tag. -->
      </video>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Abstract</h2>
    <p>Reasoning over long sequences of observations and actions is essential for many robotic tasks. Yet, learning effective long-context policies from demonstrations remains challenging. As context length increases, training becomes increasingly expensive due to rising memory demands, and policy performance often degrades as a result of spurious correlations. Recent methods typically sidestep these issues by truncating context length, discarding historical information that may be critical for subsequent decisions. In this paper, we propose an alternative approach that explicitly regularizes the retention of past information. We first revisit the copycat problem in imitation learning and identify an opposite challenge in recent diffusion policies: rather than over-relying on prior actions, they often fail to capture essential dependencies between past and future actions. To address this, we introduce Past-Token Prediction (PTP), an auxiliary task in which the policy learns to predict past action tokens alongside future ones. This regularization significantly improves temporal modeling in the policy head, with minimal reliance on visual representations. Building on this observation, we further introduce a multistage training strategy: pre-train the visual encoder with short contexts, and fine-tune the policy head using cached long-context embeddings. This strategy preserves the benefits of PTP while greatly reducing memory and computational overhead. Finally, we extend PTP into a self-verification mechanism at test time, enabling the policy to score and select candidates consistent with past actions during inference. Experiments across four real-world and six simulated tasks demonstrate that our proposed method improves the performance of long-context diffusion policies by 3× and accelerates policy training by more than 10×.
    </p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Analysis: Temporal Action Dependency</h2>
    <p>One major challenge in long-context imitation learning is causal confusion, where policies latch onto spurious correlations in the input context that do not truly influence expert behavior. This issue worsens with longer contexts, leading to overfitting during training and poor generalization at deployment. A classic example is copycat behavior, where the model simply mimics past actions without understanding their relationship to observations. However, our findings reveal a different trend: modern policies tend to under-utilize, rather than over-rely on, temporal action dependencies.
    </p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column has-text-centered">
        <figure class="equal-height-figure">
          <img src="./static/images/baseline_corr.png" style="height: 260px; margin-bottom: 0.2rem;" alt="Image 1 description">
          <!-- <figcaption class="has-text-left is-size-6 mt-2 mb-0 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;"> -->
          <figcaption class="has-text-left is-size-6 mb-0 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif; margin-top: 0.5rem;">
            Temporal action correlations of long-context robot policies. Contrary to regression-based policies, recent diffusion-based policies often under-utilize temporal action dependencies present in expert demonstrations.
          </figcaption>
        </figure>
      </div>
      <div class="column has-text-centered">
        <figure class="equal-height-figure">
          <img src="./static/images/ptp_corr.png" style="height: 260px; margin-bottom: 0.2rem;" alt="Image 2 description">
          <figcaption class="has-text-left is-size-6 mb-0 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif; margin-top: 0.5rem;">
          <!-- <figcaption class="has-text-left is-size-6 mt-2 mb-0 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;"> -->
            Temporal action correlations of our PTP-trained policies. As supervision over past actions increases (1, 8, 16), policy rollouts exhibit stronger temporal coherence and higher success rate.
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
      <h2 class="title is-3">Method: Past-Token Prediction</h2>
      <p>Building upon our analysis, we introduce a simple yet effective method for long-context imitation learning. At the core is Past-Token Prediction (PTP), an auxiliary objective that tasks the policy to predict both past and future actions. This task encourages the model to better capture action dependencies over time. To scale PTP efficiently, we propose a multi-stage training recipe that freezes a short-horizon encoder, caches visual features, and trains the policy head using these cached embeddings. At test time, we extend PTP into a self-verification mechanism: the policy samples multiple candidate sequences and selects the one that best reconstructs the already-executed actions.
      </p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/train.png" style="max-width: 80%;" alt="Image 1 description">
          <figcaption class="has-text-centered is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
            PTP training with cached embeddings. 
          </figcaption>
        </figure>
      </div>
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/test.png" style="max-width: 100%;" alt="Image 2 description">
          <figcaption class="has-text-centered is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
            PTP inference with self-verification. 
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Simulation Experiments</h2>
    <p>We evaluate our method on seven simulation tasks, including four from the RobotMimic benchmark and two newly designed long-horizon tasks that require historical context. Our approach significantly outperforms short-context and long-context baselines, especially in challenging manipulation scenarios.
</p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/sim_result.png" style="max-width: 80%;" alt="Image 1 description">
          <figcaption class="has-text-left is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Real-World Experiments</h2>
    <p>We evaluate our method on four real-world tasks, each requiring historical context for task completion:</p>
    <ul class="has-text-left" style="margin-left: 1.5rem; list-style-type: disc;">
      <li><em>Franka Block Move</em>: Move a block from one side to the other. History is needed to infer the correct target side.</li>
      <li><em>Franka Two Scoops</em>: Scoop and move two items to a target. History is required to keep count of how many scoops have been made.</li>
      <li><em>Franka Mug Replacement</em>: Replace an old mug with a new one. History helps distinguish between the two mugs.</li>
      <li><em>Aloha Tape Replacement</em>: Replace an old tape roll with a new one. History is necessary to identify the correct tape to remove.</li>
    </ul>
    <p>Our method consistently outperforms both short-context and long-context baselines across all four tasks.</p>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column has-text-centered">
        <figure>
          <img src="./static/images/real_result.png" style="max-width: 65%;" alt="Image 1 description">
          <figcaption class="has-text-left is-size-6 mt-2 has-text-grey has-text-weight-light" style="font-family: 'Noto Sans', serif;">
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
<!--     <h2 class="title is-3">Real-World Rollouts</h2>
    <p class="mb-4">We compare rollouts across four real-world tasks and three methods: Short-Context (No History), Long-Context (Non-PTP), and our proposed PTP method.</p>
 -->
    <!-- Table header -->
    <div class="columns has-text-centered is-mobile is-vcentered mb-3">
      <div class="column"><strong>Short-Context (Baseline)</strong></div>
      <div class="column"><strong>Long-Context (Baseline)</strong></div>
      <div class="column"><strong>Long-Context (Ours)</strong></div>
    </div>

    <!-- Row: Two Scoops -->
    <h3 class="subtitle is-6 has-text-left mb-2">Franka Two Scoops</h3>
    <div class="columns is-mobile is-vcentered video-row" data-group="row1">
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row1" preload="auto" autoplay muted playsinline>
          <!-- <source src="./static/videos/compressed_twoscoopsnohistfast.mp4" type="video/mp4"> -->
          <source src="./static/videos/twoscoopsnohistfast_5x.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row1" preload="auto" autoplay muted playsinline>
          <!-- <source src="./static/videos/compressed_twoscoopsnonptpfast.mp4" type="video/mp4"> -->
          <source src="./static/videos/twoscoopsnonptpfast_5x.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row1" preload="auto" autoplay muted playsinline>
          <!-- <source src="./static/videos/compressed_twoscoopshistfast.mp4" type="video/mp4"> -->
          <source src="./static/videos/twoscoopsptpfast_5x.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <!-- Row: Mug Replacement -->
    <h3 class="subtitle is-6 has-text-left mt-5 mb-2">Franka Mug Replacement</h3>
    <div class="columns is-mobile is-vcentered video-row" data-group="row2">
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row2" preload="auto" autoplay muted playsinline>
          <!-- <source src="./static/videos/compressed_swapmugsnohistfast_2.mp4" type="video/mp4"> -->
          <source src="./static/videos/swapmugnohistfast_5x.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row2" preload="auto" autoplay muted playsinline>
          <!-- <source src="./static/videos/compressed_swapcupsnonptpfast.mp4" type="video/mp4"> -->
          <source src="./static/videos/swapcupsnonptpfast_5x.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row2" preload="auto" autoplay muted playsinline>
          <!-- <source src="./static/videos/compressed_swapmugsptpfast.mp4" type="video/mp4"> -->
          <source src="./static/videos/swapmugsptpfast_5x.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <!-- Row: Tape Replacement -->
    <h3 class="subtitle is-6 has-text-left mt-5 mb-2">Aloha Tape Replacement</h3>
    <div class="columns is-mobile is-vcentered video-row" data-group="row3">
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row3" preload="auto" autoplay muted playsinline>
          <source src="./static/videos/aloha_replace_nohist_raw_5x_compressed.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row3" preload="auto" autoplay muted playsinline>
          <source src="./static/videos/aloha_replace_noptp_raw_5x_compressed.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column has-text-centered">
        <video class="sync-video" data-group="row3" preload="auto" autoplay muted playsinline>
          <source src="./static/videos/aloha_ptp_raw_5x_compressed.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<!-- JavaScript: Sync replay after all videos in a row finish -->
<script>
  const groupState = {};

  document.querySelectorAll('video.sync-video').forEach(video => {
    const group = video.dataset.group;

    if (!groupState[group]) {
      groupState[group] = { videos: [], ended: [] };
    }

    groupState[group].videos.push(video);

    video.addEventListener('ended', () => {
      groupState[group].ended.push(video);

      if (groupState[group].ended.length === groupState[group].videos.length) {
        // All videos in group finished
        groupState[group].videos.forEach(v => {
          v.currentTime = 0;
          v.play();
        });
        groupState[group].ended = [];
      }
    });
  });
</script>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ptp2025,
  title={Learning Long-Context Diffusion Policies via Past-Token Prediction},
  year={2025},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="content has-text-centered">
    <span class="author-block"><sup>*</sup>Equal Contribution</span>
  </div>
  <div class="container">
    <div class="content has-text-centered">
      <p>Page template adapted from <a href="https://nerfies.github.io/">Nerfies</a>.</p>
    </div>
  </div>
</footer> -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>    
    @article{2025ldp,
      title={Learning Long-Context Diffusion Policies via Past-Token Prediction},
      author={Torne, Marcel and Tang, Andy and Liu, Yuejiang and Finn, Chelsea},
      journal={arXiv preprint arXiv:2505.09561},
      year={2025},
    }
  </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="content has-text-centered">
    <span class="author-block"><sup>*</sup>Equal Contribution</span>
  </div>
  <div class="container">
    <div class="content has-text-centered">
      <p>Page template borrowed from <a href="https://nerfies.github.io/"><span class="dnerf">Nerfies</span></a> and <a href="https://bid-robot.github.io/"><span class="bid">Bidirectional Decoding</span></a>.</p>
    </div>
  </div>
</footer>

</body>
</html>
